{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the Kaggle Kernel of this notebook [here](https://www.kaggle.com/spsayakpaul/train-bit).\n",
    "\n",
    "This notebook fine-tunes a teacher model (based on [BiT ResNet101x3](https://arxiv.org/abs/1912.11370)) to further train a student using function matching (proposed in [Knowledge distillation: A good teacher is patient and consistent](https://arxiv.org/abs/2106.05237)). You can find the distillation notebook [here](https://www.kaggle.com/spsayakpaul/funmatch-distillation). To run this notebook you would need to have a billing enabled GCP account to use a GCS Bucket."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-07-24T10:03:05.823092Z",
     "iopub.status.busy": "2021-07-24T10:03:05.821778Z",
     "iopub.status.idle": "2021-07-24T10:03:14.774103Z",
     "shell.execute_reply": "2021-07-24T10:03:14.772621Z",
     "shell.execute_reply.started": "2021-07-24T10:03:05.822950Z"
    }
   },
   "outputs": [],
   "source": [
    "from kaggle_secrets import UserSecretsClient\n",
    "user_secrets = UserSecretsClient()\n",
    "user_credential = user_secrets.get_gcloud_credential()\n",
    "user_secrets.set_tensorflow_credential(user_credential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-24T10:03:14.777678Z",
     "iopub.status.busy": "2021-07-24T10:03:14.777358Z",
     "iopub.status.idle": "2021-07-24T10:03:14.988844Z",
     "shell.execute_reply": "2021-07-24T10:03:14.987727Z",
     "shell.execute_reply.started": "2021-07-24T10:03:14.777650Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# This needs to be done in order for the Hub module to communicate.\n",
    "import os\n",
    "os.environ[\"TFHUB_CACHE_DIR\"] = \"gs://funmatch-tf/model-cache-dir\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`gs://funmatch-tf` is the GCS Bucket I created beforehand. To proceed, you'd need to create a GCS Bucket with a universally unique name and replace `funmatch-tf` with it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-24T10:03:14.991058Z",
     "iopub.status.busy": "2021-07-24T10:03:14.990756Z",
     "iopub.status.idle": "2021-07-24T10:03:20.807364Z",
     "shell.execute_reply": "2021-07-24T10:03:20.806227Z",
     "shell.execute_reply.started": "2021-07-24T10:03:14.991031Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of accelerators:  8\n"
     ]
    }
   ],
   "source": [
    "try: # Cetect TPUs\n",
    "    tpu = None\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver() # TPU detection\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.TPUStrategy(tpu)\n",
    "except ValueError: # Detect GPUs\n",
    "    strategy = tf.distribute.MirroredStrategy() \n",
    "\n",
    "print(\"Number of accelerators: \", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-24T10:03:20.809841Z",
     "iopub.status.busy": "2021-07-24T10:03:20.809237Z",
     "iopub.status.idle": "2021-07-24T10:03:20.816553Z",
     "shell.execute_reply": "2021-07-24T10:03:20.815429Z",
     "shell.execute_reply.started": "2021-07-24T10:03:20.809795Z"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64 * strategy.num_replicas_in_sync\n",
    "BIGGER = 160\n",
    "RESIZE = 128\n",
    "CENTRAL_FRAC = 0.875\n",
    "AUTO = tf.data.AUTOTUNE\n",
    "\n",
    "SCHEDULE_LENGTH = 500\n",
    "SCHEDULE_BOUNDARIES = [200, 300, 400]\n",
    "SCHEDULE_LENGTH = (SCHEDULE_LENGTH * 512 / BATCH_SIZE) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading and input preprocessing\n",
    "\n",
    "To know how these TFRecords were created refer to [this notebook](https://colab.research.google.com/github/sayakpaul/FunMatch-Distillation/blob/main/tfrecords_pets37.ipynb). **Be sure to update the GCS paths.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-24T10:03:20.818770Z",
     "iopub.status.busy": "2021-07-24T10:03:20.818245Z",
     "iopub.status.idle": "2021-07-24T10:03:21.095996Z",
     "shell.execute_reply": "2021-07-24T10:03:21.094731Z",
     "shell.execute_reply.started": "2021-07-24T10:03:20.818728Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gs://funmatch-tf/train/train_pets37-0-128.tfrec',\n",
      " 'gs://funmatch-tf/train/train_pets37-1-128.tfrec',\n",
      " 'gs://funmatch-tf/train/train_pets37-10-128.tfrec',\n",
      " 'gs://funmatch-tf/train/train_pets37-11-128.tfrec',\n",
      " 'gs://funmatch-tf/train/train_pets37-12-128.tfrec']\n",
      "['gs://funmatch-tf/validation/validation_pets37-0-128.tfrec',\n",
      " 'gs://funmatch-tf/validation/validation_pets37-1-128.tfrec',\n",
      " 'gs://funmatch-tf/validation/validation_pets37-2-112.tfrec']\n",
      "['gs://funmatch-tf/test/test_pets37-0-128.tfrec',\n",
      " 'gs://funmatch-tf/test/test_pets37-1-128.tfrec',\n",
      " 'gs://funmatch-tf/test/test_pets37-10-128.tfrec',\n",
      " 'gs://funmatch-tf/test/test_pets37-11-128.tfrec',\n",
      " 'gs://funmatch-tf/test/test_pets37-12-128.tfrec']\n"
     ]
    }
   ],
   "source": [
    "# This comes from this repository https://github.com/GoogleCloudPlatform/training-data-analyst.\n",
    "def count_data_items(filenames):\n",
    "    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n",
    "    return np.sum(n)\n",
    "\n",
    "train_pattern = \"gs://funmatch-tf/train/*.tfrec\"\n",
    "train_filenames = tf.io.gfile.glob(train_pattern)\n",
    "val_pattern = \"gs://funmatch-tf/validation/*.tfrec\"\n",
    "val_filenames = tf.io.gfile.glob(val_pattern)\n",
    "test_pattern = \"gs://funmatch-tf/test/*.tfrec\"\n",
    "test_filenames = tf.io.gfile.glob(test_pattern)\n",
    "\n",
    "DATASET_NUM_TRAIN_EXAMPLES = count_data_items(train_filenames)\n",
    "STEPS_PER_EPOCH = 10\n",
    "\n",
    "pprint(train_filenames[:5])\n",
    "pprint(val_filenames[:5])\n",
    "pprint(test_filenames[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-24T10:03:21.106847Z",
     "iopub.status.busy": "2021-07-24T10:03:21.106389Z",
     "iopub.status.idle": "2021-07-24T10:03:21.125054Z",
     "shell.execute_reply": "2021-07-24T10:03:21.123801Z",
     "shell.execute_reply.started": "2021-07-24T10:03:21.106791Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to read the TFRecords, segregate the images and labels.\n",
    "def read_tfrecord(example, train):\n",
    "    features = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string), \n",
    "        \"class\": tf.io.FixedLenFeature([], tf.int64)\n",
    "    }\n",
    "    \n",
    "    example = tf.io.parse_single_example(example, features)\n",
    "    image = tf.image.decode_jpeg(example[\"image\"], channels=3)\n",
    "    \n",
    "    if train:\n",
    "        image = augment(image)\n",
    "    else:\n",
    "        image = tf.image.central_crop(image, central_fraction=CENTRAL_FRAC)\n",
    "        image = tf.image.resize(image, (RESIZE, RESIZE))\n",
    "        \n",
    "    image = tf.reshape(image, (RESIZE, RESIZE, 3))\n",
    "    image = tf.cast(image, tf.float32) / 255.0  \n",
    "    class_label = tf.cast(example[\"class\"], tf.int32)\n",
    "    return (image, class_label)\n",
    "\n",
    "# Load the TFRecords and create tf.data.Dataset\n",
    "def load_dataset(filenames, train):\n",
    "    opt = tf.data.Options()\n",
    "    opt.experimental_deterministic = False\n",
    "    \n",
    "    if not train:\n",
    "        opt.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.DATA\n",
    "    \n",
    "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO) \n",
    "    dataset = dataset.map(lambda x: (read_tfrecord(x, train)), num_parallel_calls=AUTO)\n",
    "    dataset = dataset.with_options(opt)\n",
    "    return dataset\n",
    "\n",
    "# Augmentation motivated from here:\n",
    "# https://github.com/google-research/big_transfer/blob/master/colabs/big_transfer_tf2.ipynb.\n",
    "def augment(image):\n",
    "    # Resize to a bigger shape, randomly horizontally flip it,\n",
    "    # and then take the crops. \n",
    "    image = tf.image.resize(image, (BIGGER, BIGGER))\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_crop(image, [RESIZE, RESIZE, 3])\n",
    "    return image\n",
    "\n",
    "# Batch, shuffle, and repeat the dataset and prefetch it\n",
    "# well before the current epoch ends\n",
    "def batch_dataset(filenames, train, batch_size=BATCH_SIZE):\n",
    "    dataset = load_dataset(filenames, train)\n",
    "    if train:\n",
    "        dataset = dataset.repeat(int(SCHEDULE_LENGTH * BATCH_SIZE / DATASET_NUM_TRAIN_EXAMPLES * STEPS_PER_EPOCH) + 1 + 50)\n",
    "        dataset = dataset.shuffle(BATCH_SIZE*10)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(AUTO) \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-24T10:03:21.127415Z",
     "iopub.status.busy": "2021-07-24T10:03:21.127092Z",
     "iopub.status.idle": "2021-07-24T10:03:21.564997Z",
     "shell.execute_reply": "2021-07-24T10:03:21.563936Z",
     "shell.execute_reply.started": "2021-07-24T10:03:21.127378Z"
    }
   },
   "outputs": [],
   "source": [
    "training_dataset = batch_dataset(train_filenames, True)\n",
    "validation_dataset = batch_dataset(val_filenames, False)\n",
    "test_dataset = batch_dataset(test_filenames, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-24T10:03:21.567138Z",
     "iopub.status.busy": "2021-07-24T10:03:21.566708Z",
     "iopub.status.idle": "2021-07-24T10:03:21.571589Z",
     "shell.execute_reply": "2021-07-24T10:03:21.570380Z",
     "shell.execute_reply.started": "2021-07-24T10:03:21.567087Z"
    }
   },
   "outputs": [],
   "source": [
    "# sample_images, _ = next(iter(training_dataset))\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# for n in range(25):\n",
    "#     ax = plt.subplot(5, 5, n + 1)\n",
    "#     plt.imshow(sample_images[n].numpy())\n",
    "#     plt.axis(\"off\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model related utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-24T10:03:21.573195Z",
     "iopub.status.busy": "2021-07-24T10:03:21.572901Z",
     "iopub.status.idle": "2021-07-24T10:03:21.588131Z",
     "shell.execute_reply": "2021-07-24T10:03:21.587208Z",
     "shell.execute_reply.started": "2021-07-24T10:03:21.573169Z"
    }
   },
   "outputs": [],
   "source": [
    "# Referenced from: https://github.com/google-research/big_transfer/blob/master/colabs/big_transfer_tf2.ipynb. \n",
    "class MyBiTModel(tf.keras.Model):\n",
    "    def __init__(self, num_classes, module):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        self.head = tf.keras.layers.Dense(num_classes, kernel_initializer=\"zeros\")\n",
    "        self.bit_model = module\n",
    "  \n",
    "    def call(self, images):\n",
    "        bit_embedding = self.bit_model(images)\n",
    "        return self.head(bit_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-24T10:03:21.590334Z",
     "iopub.status.busy": "2021-07-24T10:03:21.589701Z",
     "iopub.status.idle": "2021-07-24T10:03:21.603600Z",
     "shell.execute_reply": "2021-07-24T10:03:21.602064Z",
     "shell.execute_reply.started": "2021-07-24T10:03:21.590269Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define optimizer and loss\n",
    "\n",
    "lr = (1e-5 * BATCH_SIZE / 512) * strategy.num_replicas_in_sync \n",
    "\n",
    "# Decay learning rate by a factor of 10 at SCHEDULE_BOUNDARIES.\n",
    "lr_schedule = tf.keras.optimizers.schedules.PiecewiseConstantDecay(boundaries=SCHEDULE_BOUNDARIES, \n",
    "                                                                   values=[lr, lr*0.1, lr*0.001, lr*0.0001])\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=lr_schedule, momentum=0.9)\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-24T10:03:21.605229Z",
     "iopub.status.busy": "2021-07-24T10:03:21.604889Z",
     "iopub.status.idle": "2021-07-24T10:11:19.392986Z",
     "shell.execute_reply": "2021-07-24T10:11:19.391758Z",
     "shell.execute_reply.started": "2021-07-24T10:03:21.605182Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/45\n",
      "10/10 [==============================] - 208s 3s/step - loss: 3.5421 - accuracy: 0.3628 - val_loss: 3.1892 - val_accuracy: 0.6957\n",
      "Epoch 2/45\n",
      "10/10 [==============================] - 5s 502ms/step - loss: 2.9593 - accuracy: 0.7841 - val_loss: 2.4003 - val_accuracy: 0.8261\n",
      "Epoch 3/45\n",
      "10/10 [==============================] - 5s 484ms/step - loss: 2.1243 - accuracy: 0.8614 - val_loss: 1.5937 - val_accuracy: 0.8696\n",
      "Epoch 4/45\n",
      "10/10 [==============================] - 5s 490ms/step - loss: 1.3718 - accuracy: 0.8850 - val_loss: 1.0298 - val_accuracy: 0.8967\n",
      "Epoch 5/45\n",
      "10/10 [==============================] - 5s 486ms/step - loss: 0.8271 - accuracy: 0.9200 - val_loss: 0.7376 - val_accuracy: 0.9049\n",
      "Epoch 6/45\n",
      "10/10 [==============================] - 5s 495ms/step - loss: 0.6016 - accuracy: 0.9190 - val_loss: 0.5906 - val_accuracy: 0.9022\n",
      "Epoch 7/45\n",
      "10/10 [==============================] - 5s 491ms/step - loss: 0.4620 - accuracy: 0.9290 - val_loss: 0.5034 - val_accuracy: 0.9158\n",
      "Epoch 8/45\n",
      "10/10 [==============================] - 5s 501ms/step - loss: 0.3929 - accuracy: 0.9361 - val_loss: 0.4523 - val_accuracy: 0.9239\n",
      "Epoch 9/45\n",
      "10/10 [==============================] - 5s 493ms/step - loss: 0.3522 - accuracy: 0.9302 - val_loss: 0.4167 - val_accuracy: 0.9348\n",
      "Epoch 10/45\n",
      "10/10 [==============================] - 5s 498ms/step - loss: 0.2982 - accuracy: 0.9393 - val_loss: 0.3907 - val_accuracy: 0.9402\n",
      "Epoch 11/45\n",
      "10/10 [==============================] - 5s 485ms/step - loss: 0.2828 - accuracy: 0.9456 - val_loss: 0.3715 - val_accuracy: 0.9457\n",
      "Epoch 12/45\n",
      "10/10 [==============================] - 5s 505ms/step - loss: 0.2585 - accuracy: 0.9480 - val_loss: 0.3581 - val_accuracy: 0.9375\n",
      "Epoch 13/45\n",
      "10/10 [==============================] - 5s 492ms/step - loss: 0.2379 - accuracy: 0.9508 - val_loss: 0.3443 - val_accuracy: 0.9402\n",
      "Epoch 14/45\n",
      "10/10 [==============================] - 5s 494ms/step - loss: 0.2234 - accuracy: 0.9591 - val_loss: 0.3335 - val_accuracy: 0.9429\n",
      "Epoch 15/45\n",
      "10/10 [==============================] - 5s 486ms/step - loss: 0.2133 - accuracy: 0.9601 - val_loss: 0.3232 - val_accuracy: 0.9402\n",
      "Epoch 16/45\n",
      "10/10 [==============================] - 5s 497ms/step - loss: 0.1954 - accuracy: 0.9570 - val_loss: 0.3162 - val_accuracy: 0.9457\n",
      "Epoch 17/45\n",
      "10/10 [==============================] - 5s 496ms/step - loss: 0.1857 - accuracy: 0.9652 - val_loss: 0.3082 - val_accuracy: 0.9429\n",
      "Epoch 18/45\n",
      "10/10 [==============================] - 5s 496ms/step - loss: 0.1595 - accuracy: 0.9749 - val_loss: 0.3010 - val_accuracy: 0.9429\n",
      "Epoch 19/45\n",
      "10/10 [==============================] - 5s 483ms/step - loss: 0.1603 - accuracy: 0.9712 - val_loss: 0.2954 - val_accuracy: 0.9402\n",
      "Epoch 20/45\n",
      "10/10 [==============================] - 5s 505ms/step - loss: 0.1520 - accuracy: 0.9690 - val_loss: 0.2906 - val_accuracy: 0.9429\n",
      "Epoch 21/45\n",
      "10/10 [==============================] - 5s 496ms/step - loss: 0.1473 - accuracy: 0.9711 - val_loss: 0.2899 - val_accuracy: 0.9402\n",
      "Epoch 22/45\n",
      "10/10 [==============================] - 5s 490ms/step - loss: 0.1369 - accuracy: 0.9802 - val_loss: 0.2890 - val_accuracy: 0.9375\n",
      "Epoch 23/45\n",
      "10/10 [==============================] - 5s 485ms/step - loss: 0.1418 - accuracy: 0.9745 - val_loss: 0.2881 - val_accuracy: 0.9375\n",
      "Epoch 24/45\n",
      "10/10 [==============================] - 5s 491ms/step - loss: 0.1446 - accuracy: 0.9744 - val_loss: 0.2873 - val_accuracy: 0.9402\n",
      "Epoch 25/45\n",
      "10/10 [==============================] - 5s 481ms/step - loss: 0.1351 - accuracy: 0.9740 - val_loss: 0.2865 - val_accuracy: 0.9402\n",
      "Epoch 26/45\n",
      "10/10 [==============================] - 5s 499ms/step - loss: 0.1376 - accuracy: 0.9749 - val_loss: 0.2862 - val_accuracy: 0.9402\n",
      "Epoch 27/45\n",
      "10/10 [==============================] - 5s 489ms/step - loss: 0.1386 - accuracy: 0.9740 - val_loss: 0.2855 - val_accuracy: 0.9402\n",
      "Epoch 28/45\n",
      "10/10 [==============================] - 5s 504ms/step - loss: 0.1354 - accuracy: 0.9776 - val_loss: 0.2849 - val_accuracy: 0.9402\n",
      "Epoch 29/45\n",
      "10/10 [==============================] - 5s 485ms/step - loss: 0.1313 - accuracy: 0.9775 - val_loss: 0.2843 - val_accuracy: 0.9402\n",
      "Epoch 30/45\n",
      "10/10 [==============================] - 5s 493ms/step - loss: 0.1261 - accuracy: 0.9782 - val_loss: 0.2834 - val_accuracy: 0.9402\n",
      "Epoch 31/45\n",
      "10/10 [==============================] - 5s 491ms/step - loss: 0.1346 - accuracy: 0.9774 - val_loss: 0.2831 - val_accuracy: 0.9429\n",
      "Epoch 32/45\n",
      "10/10 [==============================] - 5s 492ms/step - loss: 0.1324 - accuracy: 0.9782 - val_loss: 0.2830 - val_accuracy: 0.9429\n",
      "Epoch 33/45\n",
      "10/10 [==============================] - 5s 483ms/step - loss: 0.1310 - accuracy: 0.9771 - val_loss: 0.2831 - val_accuracy: 0.9457\n",
      "Epoch 34/45\n",
      "10/10 [==============================] - 5s 491ms/step - loss: 0.1279 - accuracy: 0.9773 - val_loss: 0.2830 - val_accuracy: 0.9429\n",
      "Epoch 35/45\n",
      "10/10 [==============================] - 5s 483ms/step - loss: 0.1350 - accuracy: 0.9766 - val_loss: 0.2829 - val_accuracy: 0.9429\n",
      "Epoch 36/45\n",
      "10/10 [==============================] - 5s 493ms/step - loss: 0.1350 - accuracy: 0.9765 - val_loss: 0.2829 - val_accuracy: 0.9429\n",
      "Epoch 37/45\n",
      "10/10 [==============================] - 5s 483ms/step - loss: 0.1275 - accuracy: 0.9790 - val_loss: 0.2829 - val_accuracy: 0.9457\n",
      "Epoch 38/45\n",
      "10/10 [==============================] - 5s 491ms/step - loss: 0.1280 - accuracy: 0.9773 - val_loss: 0.2829 - val_accuracy: 0.9429\n",
      "Epoch 39/45\n",
      "10/10 [==============================] - 5s 482ms/step - loss: 0.1345 - accuracy: 0.9763 - val_loss: 0.2830 - val_accuracy: 0.9429\n",
      "Epoch 40/45\n",
      "10/10 [==============================] - 5s 492ms/step - loss: 0.1332 - accuracy: 0.9746 - val_loss: 0.2829 - val_accuracy: 0.9429\n",
      "Epoch 41/45\n",
      "10/10 [==============================] - 5s 482ms/step - loss: 0.1284 - accuracy: 0.9764 - val_loss: 0.2829 - val_accuracy: 0.9429\n",
      "Epoch 42/45\n",
      "10/10 [==============================] - 5s 489ms/step - loss: 0.1383 - accuracy: 0.9738 - val_loss: 0.2830 - val_accuracy: 0.9429\n",
      "Epoch 43/45\n",
      "10/10 [==============================] - 5s 482ms/step - loss: 0.1371 - accuracy: 0.9724 - val_loss: 0.2828 - val_accuracy: 0.9457\n",
      "Epoch 44/45\n",
      "10/10 [==============================] - 5s 499ms/step - loss: 0.1302 - accuracy: 0.9756 - val_loss: 0.2829 - val_accuracy: 0.9457\n",
      "Epoch 45/45\n",
      "10/10 [==============================] - 5s 483ms/step - loss: 0.1408 - accuracy: 0.9722 - val_loss: 0.2830 - val_accuracy: 0.9429\n"
     ]
    }
   ],
   "source": [
    "# Target is 91.03%.\n",
    "with strategy.scope():\n",
    "    model_url = \"https://tfhub.dev/google/bit/m-r101x3/1\"\n",
    "    module = hub.KerasLayer(model_url, trainable=True)\n",
    "    model = MyBiTModel(num_classes=37, module=module)\n",
    "    model.compile(optimizer=optimizer,\n",
    "              loss=loss_fn,\n",
    "              metrics=[\"accuracy\"])\n",
    "    \n",
    "history = model.fit(\n",
    "    training_dataset,\n",
    "    validation_data=validation_dataset,\n",
    "    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "    epochs=45\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should have trained for five more epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-24T10:11:19.394753Z",
     "iopub.status.busy": "2021-07-24T10:11:19.394457Z",
     "iopub.status.idle": "2021-07-24T10:11:47.569588Z",
     "shell.execute_reply": "2021-07-24T10:11:47.568242Z",
     "shell.execute_reply.started": "2021-07-24T10:11:19.394726Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 28s 2s/step - loss: 0.2997 - accuracy: 0.9092\n",
      "Test top-1 accuracy: 90.92%\n"
     ]
    }
   ],
   "source": [
    "_, accuracy = model.evaluate(test_dataset)\n",
    "print(f\"Test top-1 accuracy: {round(accuracy * 100, 2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-24T10:11:47.571377Z",
     "iopub.status.busy": "2021-07-24T10:11:47.570915Z",
     "iopub.status.idle": "2021-07-24T10:12:52.284721Z",
     "shell.execute_reply": "2021-07-24T10:12:52.283503Z",
     "shell.execute_reply.started": "2021-07-24T10:11:47.571322Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save(\"gs://funmatch-tf/models/T-r101x3-128\")"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-cpu.2-4.m69",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-cpu.2-4:m69"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
